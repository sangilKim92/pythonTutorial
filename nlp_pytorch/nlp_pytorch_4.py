'''
전처리 Part
크롤링 허용 여부는 사이트의 robots.txt 를 보면 알 수 있다.
ex) www.ted.com/robots.txt

노이즈를 제거하려면 인덱스의 사용이 필수적이다.
인덱스 사용을 위한 정규 표현식 예제
'''
from torch

english='[a-z]' # a~z까지 영어만 표현
not_eng='[^a-z]'# a~z를 제외한 문자식 표현
group1='[(x)(yz)]'# 그룹 x, yz를 표현
ques='x?' # 앞의 수식하는 부분이 나타나지 않거나 한번만 나타날 때는 ? 사용
plus = 'x+' # 앞의 수식하는 부분이 한 번 이상 나타날 경우 '+' 사용
mul = 'x*' # 앞의 수식하는 부분이 나타나지 않거나 여러번 나올 경우 '*' 사용
exaNum='x{n}' #앞의 수식하는 부분을 정확히 아는 경우
moreNum='x{n,}' #앞의 수식하는 부분이 n이상인 경우
startEnd='[^x$]' #^로 시작하고 $로 라인을 끝낸다.
#지정 문자 사용 \s(공백 문자), \S(공백 문자를 제외한 모든 문자), \w(알파벳, 숫자), \W(알파벳, 숫자 제외), \d(숫자), \D(숫자 제외)

'''
문장 단위 분절을 해줄 필요가 있다.
기본적으로 .으로 문장은 구분되지만, 숫자에 3.14와 같은 숫자도 .으로 구분하며 영어 약어도 .으로 구분된다. 이런 복잡성 때문에
라이브러리를 사용하는게 정확하다. 
nltk 사용

한국어의 토큰화는 가장 좋은 성능을 보이는 Mecab
영어의 토큰화는 Moses ( 기존에 nltk에서 제공됐지만, 최신버전에는 없어졌다.)
중국어의 토큰화는 JIEBA등을 사용하면 된다.

이렇게 토큰화한 언어는 임베딩 벡터로 들어가 벡터화시킨다.
페이스북의 MUSE를 이용해 나라의 단어 벡터끼리 맵핑하는 작업을 진행한다.

나라간의 단어를 맵핑시켰다면 이제 문장에 대해 진행해야 한다.

문장은 오픈라이브러리 CTK를 이용해서 진행한다. 

서브워드 분절
영어나 한국어같은 언어는 라틴어와 한자로 구성되었기에 단어를 쪼갤 수 있다.
쪼개진 단어는 어원이라고 불리는데 이렇게 어원의 형태로 바꾸고 접두사, 접미사를 구분했을 떄, 처음 보는 단어가 나타나도
어원을 파악하여 오류가 적어진다.
주의할점은 서브웨이 분절로 공백을 나타내면 기존의 공백과 구분이 안가기에 자신이 특정한 문자로 바꾸어 주는것이 좋다.

토치텍스트: 텍스트 전처리 코드를 모아둔 라이브러리. 사용하면 좋다.

'''



class parent():
    def __init__(self):
        print("parent")

class child(parent):
    def __init__(self):
        super(child,self).__init__()
        #super(self).__init__()
        #parent.__init__(self)
        #super(x)__init__() == parent.__init__(x)
        print("child")

child()