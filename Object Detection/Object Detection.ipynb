{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "- window 를 잘개 쪼개면서 하던 전통적인 방식에서 Selective Search로 발전함\n",
    "- Selective Search는 픽셀값과 모양을 토대로 bounding box를 추천하는 것(region proposal)\n",
    "\n",
    "- Selective Search의 성능을 확인하는 용도로 Iou가 사용됨\n",
    "- Intersection over union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non max Suppression\n",
    "- Selective Search를 사용하면 여러 개의 bounding box가 생성된다.\n",
    "- 이 여러 개의 box중에 가장 적한 것을 남기고 삭제하는 것을 Non max Suppression \n",
    "- NMS (눌러준다) 적당한것을 찾기 위해 눌러준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object detecion의 성능 평가는 precsion과 recall로 판가름난다.\n",
    "# 찾은 물체를 정확히 찾았는지, 있는 물체를 다 찾았는지 이다.\n",
    "# confidence 임계값에 따라 박스를 많이 생성하는 재현률은 높아지고 정확도는 떨어진다. 이 confidence를 설정하는 것도 중요하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object detection 데이터는 유명한거로 PASCAL과 COCO등이 있다.\n",
    "#PASCAL은 XML형태로 제공해주고 COCO는 json파일로 제공해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python 기반 주요 라이브러리\n",
    "#pil, scikit image, opencv\n",
    "#opencv 가 대세 가장 대중적임\n",
    "\n",
    "\n",
    "#opencv 의 가장 큰 문제점  RGB ->  BGR 로 보여줌 imread()로 불러올시\n",
    "# 붉은 계열을 파란 계열로 불러옴\n",
    "\n",
    "#imwrite()를 사용하면 BGR 을 다시 RGB로 바꾸기에 변화가 없다고 느낌\n",
    "\n",
    "#opencv cv 의  window framework을 대신 사용하기 위해 import matplotlib.pypylot 를 대신 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 파일을 변환하는 방법\n",
    "\n",
    "### 기본적으로 이미지를  numpy로 받고 reshape하면 이미지가 변화한다.\n",
    "### 이를 예방하고 적당한 사이즈로 바꾸기 위해선 opencv, skimage, PIL 라이브러리를 사용해서 이미지 사이즈를 변화하면 된다.\n",
    "### 혼자서 구현하기는 어렵다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.VideoCapture, cv2.VideoWriter 를 이용해서 동영상을 찍고 저장한다.\n",
    "# videowriter은 coding과 사이즈를 따로 설정가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CUDA, GPU를 다루기 위한 표준 언어를 사용할 수 있는 기술\n",
    "- C, python도 지원\n",
    "- CUDA DRIVER가 GPU를 조작할 수 있도록 해줌\n",
    "\n",
    "- cuDNN (CUDA의 딥러닝 라이브러리)\n",
    "- nvidia-smi 현재 gpu를 모니터링해주는 예약어\n",
    "- watch -n1 nvidia-smi 1초 간격으로 표를 보여준다.\n",
    "- GPU사용량이 꽉차서 서버가 죽을 수 있으니 주의 필요하다.\n",
    "\n",
    "\n",
    "# OBJECT DETECTION\n",
    "\n",
    "## FEATURED EXTRACTER NETWORK(VGG,CNN)을 이용해서 특징을 뽑고\n",
    "## OBJECT DETECTION NETWORK에서 뽑는다.\n",
    "## REGION  PROPOSAL \n",
    "### 크게 3단계로 구분된다.\n",
    "\n",
    "\n",
    "- FPS 는 초당 프레임으로 얼마나 빠르게 Object를 찾는지를 의미하고\n",
    "- detection은 이미지 데이터가 클수록 잘 찾기 때문에 느리지만 성능이 좋아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 픽셀을 sliding window 방식으론 문제가 많기에 색깔이나 엣지들로 obejct detecion을 시행한다.\n",
    "- selective search를 시행한다. 픽셀이나 엣지들로 2000개 정도 뽑아낸다.\n",
    "- 그 2000개의 영역에 CNN을 이용해 특징을 뽑아내고 classification을 진행한다.\n",
    "- SVM Classifier로 이미지가 무엇인지 선택, 이미지의 특징을 뽑는 CNN은 모든 이미지의 사이즈가 같아야 한다.\n",
    "- 따라서, 기본적으로 warp과 image crop이 진행된다. 이미지가 찌그러지거나 잘라진다.\n",
    "- 여러 개의 bounding box를 계산해야 하기에 시간이 오래 걸린다.\n",
    "- 복잡한 아키텍처와 너무 느리다. 하지만 동시대 알고리즘 대비 꽤 높은 정확도\n",
    "- R-CNN이후 딥러닝 기반으로 Object detection의 방향이 정해졌다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SPPNET은 기존의 selective search의 2000개에 CNN을 적용하는 것을 조금 변형해\n",
    "- 기존 이미지에만 CNN을 적용하고 selective search에다가 매핑하는 것이다.\n",
    "- 여기서 문제는 selective search한 것들은 전부 이미지 사이즈가 다른데 그걸 이미지를 맞추어는 net을 따로 만들어 둔걸 SPPNET이라고 한다.\n",
    "- 느린 계산을 보완한 것이다.\n",
    "- SMP은 Bag of word의 기법을 따라해서 영역을 나누고 그 영역안에 특정 픽셀이 몇개가 들어갔는지 센다. 위치는 고려하지 않고 숫자만 세서 \n",
    "- 결정하기 때문에 정확도가 낮다.\n",
    "- 몇 분면으로 나눌지에 따라 벡터의 개수가 정해지기에 이미지의 개수를 정할 수 있다.\n",
    "- 12:8의 비율을 가지는 이미지도 결국 4분면, 16분면으로 나누면 나오는 이미지 데이터가 같기에 계산이 가능해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이렇게 원본이미지에 CNN을 적용하고 7*7 분면으로 나눈다음 맵핑하는 것을 fast rcnn이라 한다.\n",
    "- fast rcnn은 맵핑 후 classification과 regression 두개의 오차함수를 줄여 나간다.\n",
    "- SVM을 softmax로 바꿈\n",
    "- End to End Network Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster RCNN\n",
    "\n",
    "## RCNN -> Fast RCNN -> FASTER RCNN\n",
    "\n",
    "### FASTER RCNN = FAST RCNN + Region Proposal Network \n",
    "\n",
    "- fast rcnn에 region proposal 이 들어가 하나로 해결함으로써 GPU를 사용해 빠르게 연산시키는 기법\n",
    "- 맵핑 대신 CNN으로 원본이미지의 특징을 추출한것에 대해 Region proposal을 실행한다.\n",
    "- 그 다음 뽑은 resion proposal의 출력 차원을 맞추기 위해 Roi pooling을 진행한다.\n",
    "- Anchor box가 사용된다. CNN으로 특징을 추출한 것에서 Region proposal이 힘들어지기에 Anchor box로  뽑은 것에다가 신경망 계산을 지속적으로 하며 Classification과 softmax의 오차를 줄여나간다.\n",
    "- Anchor box를 만들 때는 원본이미지를 16분면으로 가로 세로를 나누고 그렇게 나눈 각 각의 featured 픽셀에다 9개씩 Anchor box를 적용한다.\n",
    "- 그러면 Anchor box가 너무 많아지므로 이 중에서 Object Detection을 수행할만한 것만 추리는 Region proposal를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
